{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a617f86",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120aebf",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "from tqdm.auto import tqdm, trange\n",
    "import control\n",
    "import notebook_setup\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from commonml.helpers.logs import get_tensorboard_scalar_frame\n",
    "\n",
    "from systems.base import SystemEnv\n",
    "from systems.plotting import (\n",
    "    plot_env_response,\n",
    "    multiple_response_plots\n",
    ")\n",
    "from rl import learn_rl, transform_rl_policy, evaluate_rl\n",
    "from xform import (\n",
    "    policy_transform,\n",
    "    pseudo_matrix,\n",
    "    ab_xform_from_pseudo_matrix,\n",
    "    basis_vectors,\n",
    "    is_controllable,\n",
    "    get_env_samples\n",
    ")\n",
    "from mpcontrol import evaluate_mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbae3b5",
   "metadata": {},
   "source": [
    "# Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b666a1f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Simple system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535001e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\begin{align}\n",
    "\\dot{y_1} &= a \\cdot x + b \\cdot u(t) \\\\\n",
    "&= [a]y + [b] u(t)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1513092",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_simple(a, b, name='simple'):\n",
    "    A = np.asarray([[a]], dtype=np.float32)\n",
    "    B = np.asarray([[b]], dtype=np.float32)\n",
    "    C = np.eye(1, dtype=np.float32)\n",
    "    D = np.zeros((1,1), dtype=np.float32)\n",
    "    return control.ss(A, B, C, D, name=name)\n",
    "\n",
    "sim = create_simple(-0.1, 1)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18843d8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleEnv(SystemEnv):\n",
    "    def __init__(self, a, b, q=1, dt=0.01, seed=None):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        system = create_simple(a, b)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.period = int((2/np.abs(a)) / dt)\n",
    "        super().__init__(system, q, dt, seed)\n",
    "    def reset(self, x=None):\n",
    "        super().reset(x)\n",
    "        self.x = (np.asarray(x) or \\\n",
    "             self.random.uniform(\n",
    "            -1/(2*np.abs(self.a)),\n",
    "             1/(2*np.abs(self.a)),\n",
    "             size=(1,)\n",
    "            )).astype(np.float32)\n",
    "        return self.x\n",
    "    def step(self, u: np.ndarray, from_x=None, persist=True):\n",
    "        x, r, d, i = super().step(u, from_x=from_x, persist=persist)\n",
    "        return x, r, self.n > self.period, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f54a91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, u, r = [], [], []\n",
    "r_ = []\n",
    "env = SimpleEnv(-0.1, 1)\n",
    "x.append(env.reset([-1])[0])\n",
    "for i in range(int(env.period * 5)):\n",
    "    #u.append(np.sin(i * 2 * np.pi /env.period))\n",
    "    u.append(-np.sign(x[-1]))\n",
    "    state, reward, *_ = env.step([u[-1]])\n",
    "    x.append(state[0])\n",
    "    r.append(reward)\n",
    "plt.plot(x, label='x')\n",
    "# plt.plot(u, label='u')\n",
    "lines = plt.gca().lines\n",
    "plt.twinx()\n",
    "plt.plot(r, label='r', c='g')\n",
    "plt.legend(handles = plt.gca().lines + lines)\n",
    "print(sum(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880e9f1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Spring-mass system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7c59",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "m\\ddot{x} = -kx -k_f\\dot{x} + u(t)\n",
    "$$\n",
    "\n",
    "This is a 2nd order ODE. Linearizing it, by letting $y_1 = x, y_2 = \\dot{x}$. Then:\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{y}_1 &= 0y_1 + y_2 \\\\\n",
    "\\dot{y}_2 &= -(k/m)y_1 - (k_f/m)y_2  + u(t)/m\n",
    "\\end{align}\n",
    "\n",
    "In state space form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\\dot{y}_1 \\\\ \\dot{y}_2 \\end{bmatrix} = \n",
    "\\begin{bmatrix}0 & 1 \\\\ -k/m & -k_f/m \\end{bmatrix}\n",
    "\\begin{bmatrix}y_1 \\\\ y_2 \\end{bmatrix} + \n",
    "\\begin{bmatrix}0 \\\\ 1/m\\end{bmatrix}\n",
    "\\begin{bmatrix}u(t)\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df0e6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_spring(k, m, df=0.02, name='spring'):\n",
    "    A = np.asarray([[0, 1], [-k/m, -df/m]], dtype=np.float32)\n",
    "    B = np.asarray([[0], [1/m]], dtype=np.float32)\n",
    "    C = np.eye(2, dtype=np.float32)\n",
    "    D = np.zeros((2,1), dtype=np.float32)\n",
    "    return control.ss(A, B, C, D, name=name)\n",
    "\n",
    "spr = create_spring(1,0.1)\n",
    "spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf77f82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SpringMassEnv(SystemEnv):\n",
    "    def __init__(self, k, m, df=0.02, q=((1,0),(0,1)), dt=0.01, seed=None):\n",
    "        system = create_spring(k, m, df=df)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.period = int(np.pi * 2 * np.sqrt(m / k) / dt)\n",
    "        super().__init__(system, q, dt, seed)\n",
    "    def reset(self, x=None):\n",
    "        super().reset(x)\n",
    "        self.x = (np.asarray(x) if x is not None else \\\n",
    "                 self.random.uniform([-1, -0.1], [1, 0.1])\n",
    "                 ).astype(np.float32)\n",
    "        return self.x\n",
    "    def step(self, u: np.ndarray, from_x=None, persist=True):\n",
    "        x, r, d, i = super().step(u, from_x=from_x, persist=persist)\n",
    "        return x, r, self.n > self.period, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a740fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, v, r = [], [], []\n",
    "env = SpringMassEnv(4,0.2,0.01)\n",
    "env.reset([-0.5, 0])\n",
    "for _ in range(int(env.period * 5)):\n",
    "    action = -1 * np.sign(env.x[1:])\n",
    "    state, reward, *_ = env.step(action)\n",
    "    x.append(state[0])\n",
    "    v.append(state[1])\n",
    "    r.append(reward)\n",
    "plt.plot(x, label='x')\n",
    "plt.plot(v, label='v')\n",
    "plt.legend()\n",
    "plt.twinx()\n",
    "plt.plot(r, label='reward', c='g')\n",
    "plt.legend()\n",
    "print(np.sum(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3daff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pendulum system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad59c2f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The state of a pendulum is defined by the angle $\\theta$, where the action $u(t)$ is the torque being applied to the pendulum:\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{y_1} &= \\dot{\\theta} =& y_2 \\\\\n",
    "\\dot{y_2} &= \\ddot{\\theta} =& -\\frac{g}{l}\\sin\\theta + \\frac{u(t) -k_f\\dot{\\theta}}{ml^2}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\\dot{y}_1 \\\\ \\dot{y}_2 \\end{bmatrix} = \n",
    "\\begin{bmatrix}0 & 1 \\\\ -g\\sin(\\cdot)/l & -k_f/ml^2 \\end{bmatrix}\n",
    "\\begin{bmatrix}y_1 \\\\ y_2 \\end{bmatrix} + \n",
    "\\begin{bmatrix}0 \\\\ 1/ml^2\\end{bmatrix}\n",
    "\\begin{bmatrix}u(t)\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f957f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_pendulum(m, l, g, df=0.02, name='pendulum',\n",
    "                    xformA=np.eye(2, dtype=np.float32),\n",
    "                    xformB=np.eye(2, dtype=np.float32)):\n",
    "    g_l = -g / l\n",
    "    ml2_inv = 1 / (m * l**2)\n",
    "    def updfcn(t, x, u, params):\n",
    "        if x.ndim==2:\n",
    "            x = x.squeeze()\n",
    "            u = np.atleast_1d(u.squeeze())\n",
    "        Ax = np.asarray(\n",
    "            [[0, x[1]],\n",
    "             [g_l * np.sin(x[0]), -df * x[1] * ml2_inv]],\n",
    "            dtype=np.float32).sum(axis=1)\n",
    "        Bu = np.asarray(\n",
    "            [[0],\n",
    "             [u[0] * ml2_inv]],\n",
    "            dtype=np.float32).sum(axis=1)\n",
    "        return xformA @ Ax + xformB @ Bu\n",
    "    def outfcn(t, x, u, params):\n",
    "        return x\n",
    "    sys = control.NonlinearIOSystem(updfcn, outfcn, name=name,\n",
    "                                    inputs=1, outputs=2, states=2)\n",
    "    return sys\n",
    "pend = create_pendulum(0.1, 1, 10)\n",
    "pend.linearize(np.asarray([np.pi/2,0]), np.asarray([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99ecff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PendulumEnv(SystemEnv):\n",
    "    def __init__(\n",
    "        self, m, l, g, df=0.02, q=((10,0),(0,0.1)), dt=0.01,\n",
    "        seed=None, xformA=np.eye(2), xformB=np.eye(2)\n",
    "    ):\n",
    "        system = create_pendulum(m, l, g, df=df, xformA=xformA, xformB=xformB)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.period = int(np.pi * 2 * np.sqrt(l / g) / dt)\n",
    "        super().__init__(system, q, dt, seed)\n",
    "    def reset(self, x=None):\n",
    "        super().reset(x)\n",
    "        self.x = (np.asarray(x) if x is not None else \\\n",
    "                 self.random.uniform([-np.pi/6, -0.05], [np.pi/6, 0.05])\n",
    "                 ).astype(np.float32)\n",
    "        return self.x\n",
    "    def step(self, u: np.ndarray, from_x=None, persist=True):\n",
    "        x, r, d, i = super().step(u, from_x=from_x, persist=persist)\n",
    "        if x.ndim==1:\n",
    "            x[0] = np.sign(x[0]) * (np.abs(x[0]) % (2 * np.pi))\n",
    "            if persist:\n",
    "                self.x[0] = x[0]\n",
    "        elif x.ndim==2:\n",
    "            x[0,0] = np.sign(x[0,0]) * (np.abs(x[0,0]) % (2 * np.pi))\n",
    "            if persist:\n",
    "                self.x[0,0] = x[0,0]\n",
    "        return x, r, self.n > self.period, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40ea2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, v, r = [], [], []\n",
    "env = PendulumEnv(m=0.1, l=1., g=10, df=0.02, xformA=xformA, xformB=xformB)\n",
    "env.reset([0.1, 0])\n",
    "for _ in range(int(env.period * 2)):\n",
    "    action = -1 * np.sign(env.x[1:])\n",
    "    state, reward, *_ = env.step(action)\n",
    "    x.append(state[0])\n",
    "    v.append(state[1])\n",
    "    r.append(reward)\n",
    "plt.plot(x, label='theta')\n",
    "plt.plot(v, label='theta_dot')\n",
    "plt.legend()\n",
    "plt.twinx()\n",
    "plt.plot(r, label='reward', c='g')\n",
    "plt.legend()\n",
    "print(sum(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6aaf0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Cart-pole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc4985",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The state of an inverted pendulum system is defined by the linear and angular accelerations $\\ddot{x}, \\ddot{\\theta}$. $x$ is positive right, $\\theta$ is positive counter-clockwise.\n",
    "\n",
    "Then, linearizing it by assuming $y_1=\\theta, y_2=\\dot{\\theta}, y_3=x, y_4=\\dot{x}$\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{y_1} &= \\dot{\\theta} =& y_2 \\\\\n",
    "\\dot{y_2} &= \\ddot{\\theta} =& \\frac{g}{l}\\sin y_1 - \\frac{k_f y_2}{ml^2} + \\frac{\\dot{y_4}\\cos y_1}{l} \\\\\n",
    "\\dot{y_3} &= \\dot{x} =& y_4 \\\\\n",
    "\\dot{y_4} &= \\ddot{x} =& \\frac{m_p \\sin y_1\\left(g\\cos y_1-l\\dot{y_1}^2\\right) + u(t)}{m_c+m_p-m_p\\cos^2 y_1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b044a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_cartpole(mc, mp, l, g, df=0.01, name='cartpole',\n",
    "                   xformA=np.eye(4), xformB=np.eye(4)):\n",
    "    g_l = g / l\n",
    "    ml2_inv = 1 / (mp * l**2)\n",
    "    def updfcn(t, x, u, params):\n",
    "        if x.ndim==2:\n",
    "            # for MPC simulations\n",
    "            u = np.atleast_1d(u.squeeze())\n",
    "            x1,x2,x3,x4=x.squeeze() # theta, theta_dot, x, x_dot\n",
    "        elif x.ndim==1:\n",
    "            x1,x2,x3,x4=x # theta, theta_dot, x, x_dot\n",
    "        cx1, sx1 = np.cos(x1), np.sin(x1)\n",
    "        x4_denom = mc + mp - mp * cx1**2\n",
    "        # delta x due to state\n",
    "        x1_ = x2\n",
    "        x2_ = (g_l * sx1) - (df * ml2_inv * x2) + \\\n",
    "              ((cx1 / l) * ((mp * sx1 * (g*cx1 - l * x2**2)) / x4_denom))\n",
    "        x3_ = x4\n",
    "        x4_ = (mp * sx1 * (g*cx1 - l * x2**2)) / x4_denom\n",
    "        dx_x = np.asarray([x1_, x2_, x3_, x4_], dtype=np.float32)\n",
    "        # delta x due to action. Factoring out parts in u\n",
    "        x1_ = 0\n",
    "        x2_ = (cx1 / l) * (u[0]) / x4_denom\n",
    "        x3_ = 0\n",
    "        x4_ = u[0] / x4_denom\n",
    "        dx_u = np.asarray([x1_, x2_, x3_, x4_], dtype=np.float32)\n",
    "        return xformA @ dx_x + xformB @ dx_u\n",
    "    def outfcn(t, x, u, params):\n",
    "        return x\n",
    "    sys = control.NonlinearIOSystem(updfcn, outfcn, name=name,\n",
    "                                    inputs=1, outputs=4, states=4)\n",
    "    return sys\n",
    "\n",
    "cart = create_cartpole(10, 1, 1, 10)\n",
    "cart.linearize(np.asarray([np.pi, 0, 0, 0]), np.asarray([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83e561",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CartpoleEnv(SystemEnv):\n",
    "    def __init__(self, mc, mp, l, g, df=0.01,\n",
    "                 q=((1,0,0,0),(0,0.01,0,0),(0,0,0.1,0),(0,0,0,0.01)),\n",
    "                 dt=0.01, seed=None, xformA=np.eye(4), xformB=np.eye(4)):\n",
    "        system = create_cartpole(mc, mp, l, g, df=df,\n",
    "                                 xformA=xformA, xformB=xformB)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.period = int(np.pi * 2 * np.sqrt(l / g) / dt)\n",
    "        super().__init__(system, q, dt, seed)\n",
    "    def reset(self, x=None):\n",
    "        super().reset(x)\n",
    "        self.x = (np.asarray(x) if x is not None else \\\n",
    "                 self.random.uniform(-0.05, 0.05, size=4)\n",
    "                 ).astype(np.float32)\n",
    "        return self.x\n",
    "    def reward(self, xold, u, x):\n",
    "        return 1.\n",
    "    def step(self, u: np.ndarray, from_x=None, persist=True):\n",
    "        x, r, d, i = super().step(u, from_x=from_x, persist=persist)\n",
    "        if x.ndim==1:\n",
    "            x[0] = np.sign(x[0]) * (np.abs(x[0]) % (2 * np.pi))\n",
    "            if persist:\n",
    "                self.x[0] = x[0]\n",
    "            done = (np.abs(x[0]) > 0.2095) or \\\n",
    "                   (self.n >= 500) or \\\n",
    "                   (np.abs(x[2]) > 2.4)\n",
    "        elif x.ndim==2:\n",
    "            assert not persist, '2 dim array only during MPC simulation'\n",
    "            x[0,0] = np.sign(x[0,0]) * (np.abs(x[0,0]) % (2 * np.pi))\n",
    "            done = (np.abs(x[0,0]) > 0.2095) or \\\n",
    "                   (self.n >= 500) or \\\n",
    "                   (np.abs(x[0,2]) > 2.4)\n",
    "        return x, r, done, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537ba16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "th, omega, x, v, r = [], [], [], [], []\n",
    "env = CartpoleEnv(mc=0.5, mp=0.1, l=1, g=10, df=0.01, dt=0.01)\n",
    "env.reset([np.pi/90, 0, 0, 0])\n",
    "done = False\n",
    "while not done:\n",
    "# for _ in range(int(5 * env.period)):\n",
    "    action = -0.5 * np.sign(env.x[0:1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    th.append(state[0])\n",
    "    omega.append(state[1])\n",
    "    x.append(state[2])\n",
    "    v.append(state[3])\n",
    "    r.append(reward)\n",
    "plt.plot(np.asarray(th) * 180 / np.pi, label='theta', c='r')\n",
    "plt.plot(np.asarray(omega) * 180 / np.pi, label='theta_dot', c='r', ls=':')\n",
    "lines = plt.gca().lines\n",
    "plt.ylabel('Angles /deg')\n",
    "plt.twinx()\n",
    "plt.plot(x, label='x', c='b')\n",
    "plt.plot(v, label='x_dot', c='b', ls=':')\n",
    "plt.plot(r, label='reward')\n",
    "plt.ylabel('Position')\n",
    "plt.legend(handles = plt.gca().lines + lines)\n",
    "print(sum(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89fd03",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2052a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LQR functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85e904",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_law(\n",
    "    systems, x0_fn, q, r=None, ks=None, dt=0.01,\n",
    "    t_final=10, plot=False, n=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare cost of using LQR trained on one system over others.\n",
    "    The cost calculated is solely a function of state, and not action.\n",
    "    If a system is optimized, it should have the control law\n",
    "    as feedback already.\n",
    "    \"\"\"\n",
    "    c = []\n",
    "    for i in range(n):\n",
    "        x0 = x0_fn() if callable(x0_fn) else x0_fn\n",
    "        costs = []\n",
    "        for i, s in enumerate(systems):\n",
    "            if isinstance(s, control.NonlinearIOSystem):\n",
    "                resp = control.input_output_response(\n",
    "                    s, np.linspace(0, t_final, int(t_final/dt)), U=0, x0=x0)\n",
    "            else:\n",
    "                resp = control.initial_response(\n",
    "                    s, np.linspace(0, t_final, int(t_final/dt)), x0)\n",
    "            t, y, x = resp.time, resp.outputs, resp.states\n",
    "            cost = (x.T @ q @ x).diagonal().sum()\n",
    "            if ks is not None:\n",
    "                if isinstance(ks, (list, tuple)):\n",
    "                    ki = ks[i]\n",
    "                else:\n",
    "                    ki = ks\n",
    "                u = - ki @ x\n",
    "                cost += (u.T @ r @ u).diagonal().sum()\n",
    "            costs.append(cost)\n",
    "        c.append(costs)\n",
    "    cmean, cstd = np.mean(c, axis=0), np.std(c, axis=0)\n",
    "    if plot:\n",
    "        s = [20 if i==0 else 10 for i in range(len(systems))]\n",
    "        c= ['r' if i==0 else 'b' for i in range(len(systems))]\n",
    "        plt.scatter(np.arange(i+1), cmean, s=s, c=c)\n",
    "        plt.ylabel('Cost')\n",
    "        for j in range(len(systems)):\n",
    "            plt.text(j, costs[j], '%s:\\n%.2f' % (systems[j].name, costs[j]))\n",
    "        plt.errorbar(np.arange(i+1), cmean, yerr=cstd, ecolor=c)\n",
    "    return cmean, cstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb64712",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_lqr(law: np.ndarray, env, n_eval_episodes=10,\n",
    "                 clip_actions=True):\n",
    "    R = []\n",
    "    start = time.time()\n",
    "    for e in range(n_eval_episodes):\n",
    "        x, u, r = [], [], []\n",
    "        x.append(env.reset())\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = -law @ x[-1]\n",
    "            if clip_actions:\n",
    "                action = np.clip(action,\n",
    "                    a_min=env.action_space.low,\n",
    "                    a_max=env.action_space.high\n",
    "                )\n",
    "            u.append(action)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            r.append(reward)\n",
    "            if done: break\n",
    "            x.append(state)\n",
    "        R.append(sum(r))\n",
    "    end = time.time()\n",
    "    runtime = (end - start) / n_eval_episodes\n",
    "    return np.mean(R), np.std(R), runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59acb7",
   "metadata": {},
   "source": [
    "# Policy transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39868f30",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## System specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a3695",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sys_kwargs = dict(a=-0.1, b=1)\n",
    "# learn_kwargs = dict(steps=200_000, seed=0, learning_rate=5e-3,\n",
    "#                     n_steps=4000, batch_size=200, n_epochs=10,\n",
    "#                     gamma=0.)\n",
    "# q, r = np.asarray([[1]]), np.asarray([[0.00001]])\n",
    "# xformA = np.asarray([[0.5]])\n",
    "# xformB = np.asarray([[-0.5]])\n",
    "# x0 = np.asarray([-2.5])\n",
    "# make_env = lambda: SimpleEnv(**sys_kwargs, q=q, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = make_env()\n",
    "#     env.system.A = xformA @ env.system.A\n",
    "#     env.system.B = xformB @ env.system.B\n",
    "#     return env\n",
    "# sys = create_simple(**sys_kwargs, name='simple')\n",
    "# env = make_env()\n",
    "\n",
    "sys_kwargs = dict(k=4, m=0.2, df=0.01)\n",
    "learn_kwargs = dict(steps=100_000, seed=0, learning_rate=2e-3,\n",
    "                    n_steps=2048, batch_size=64, n_epochs=10,\n",
    "                    gamma=0.)\n",
    "q, r = np.asarray([[1,0], [0,1]]), np.asarray([[0.00001]])\n",
    "angA, angB = np.pi/4, np.pi\n",
    "scalarA, scalarB = 0.8, 0.5\n",
    "xformA = np.asarray([[np.cos(angA), -np.sin(angA)],\n",
    "                    [np.sin(angA), np.cos(angA)]]).T \\\n",
    "        @ (np.eye(2) * scalarA)\n",
    "xformB = np.asarray([[np.cos(angB), -np.sin(angB)],\n",
    "                    [np.sin(angB), np.cos(angB)]]).T \\\n",
    "        @ (np.eye(2) * scalarB)\n",
    "x0 = np.asarray([-0.5, 0])\n",
    "make_env = lambda: SpringMassEnv(**sys_kwargs, q=q, seed=0)\n",
    "def make_xform_env():\n",
    "    env = make_env()\n",
    "    env.system.A = xformA @ env.system.A\n",
    "    env.system.B = xformB @ env.system.B\n",
    "    return env\n",
    "env = make_env()\n",
    "sys = create_spring(**sys_kwargs)\n",
    "\n",
    "# sys_kwargs = dict(m=0.1, l=1, g=10., df=0.02)\n",
    "# learn_kwargs = dict(steps=200_000, seed=0, learning_rate=1e-3,\n",
    "#                     n_steps=2048, batch_size=128, n_epochs=10,\n",
    "#                     gamma=0.99)\n",
    "# q, r = np.asarray([[10,0], [0,1e-1]]), np.asarray([[0.00001]])\n",
    "# angA, angB = np.pi/4, np.pi\n",
    "# scalarA, scalarB = 0.8, 0.5\n",
    "# xformA = np.asarray([[np.cos(angA), -np.sin(angA)],\n",
    "#                     [np.sin(angA), np.cos(angA)]]).T \\\n",
    "#         @ (np.eye(2) * scalarA)\n",
    "# xformB = np.asarray([[np.cos(angB), -np.sin(angB)],\n",
    "#                     [np.sin(angB), np.cos(angB)]]).T \\\n",
    "#         @ (np.eye(2) * scalarB)\n",
    "# x0 = np.asarray([-0.5, 0])\n",
    "# make_env = lambda: PendulumEnv(**sys_kwargs, q=q, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = PendulumEnv(**sys_kwargs, q=q, seed=0,\n",
    "#                       xformA=xformA, xformB=xformB)\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_pendulum(**sys_kwargs)\n",
    "\n",
    "# sys_kwargs = dict(mc=0.5, mp=0.1, l=1, g=10, df=0.01)\n",
    "# learn_kwargs = dict(steps=400_000, seed=0, learning_rate=2e-3,\n",
    "#                     n_steps=2048, batch_size=64, n_epochs=10,\n",
    "#                     gamma=0.99)\n",
    "# q = np.asarray([[1,0,0,0], [0,0.1,0,0],[0,0,1e-5,0],[0,0,0,1e-1]])\n",
    "# r = np.asarray([[0.00001]])\n",
    "# xformA = np.diagflat(np.random.RandomState(seed=0).randn(4))\n",
    "# xformB = np.diagflat(np.random.RandomState(seed=1).randn(4))\n",
    "# x0 = np.asarray([-np.pi/45, 0, 0, 0])\n",
    "# make_env = lambda: CartpoleEnv(**sys_kwargs, q=q, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = CartpoleEnv(**sys_kwargs, q=q, seed=0,\n",
    "#                       xformA=xformA, xformB=xformB)\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_cartpole(**sys_kwargs)\n",
    "\n",
    "# sys_kwargs = dict(vp=vp, sp=sp)\n",
    "# learn_kwargs = dict(steps=200_000, seed=0, learning_rate=2e-4, n_steps=2000,\n",
    "#                    gamma=0.8)\n",
    "# q = np.diagflat([1,1,1,0.1,0.1,0.1,1,1,1,0.1,0.1,0.1])\n",
    "# r = np.eye(4) * 1e-4\n",
    "# xformA = np.random.RandomState(seed=0).randn(12,12)\n",
    "# xformB = np.diagflat(np.random.RandomState(seed=1).randn(4))\n",
    "# x0 = np.zeros(12, dtype=np.float32)\n",
    "# make_env = lambda: MultirotorEnv(**sys_kwargs, seed=0)\n",
    "# def make_xform_env():\n",
    "#     env = MultirotorEnv(**sys_kwargs, q=q, seed=0,\n",
    "#                       xformA=xformA, xformB=xformB)\n",
    "#     return env\n",
    "# env = make_env()\n",
    "# sys = create_multirotor(**sys_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd45d4",
   "metadata": {},
   "source": [
    "## Linear Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38fa63",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation w/ LQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23abc9",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_xform_env()\n",
    "if not isinstance(env.system, control.LinearIOSystem):\n",
    "    warnings.warn(('Must be a linear system in StateSpace from. '\n",
    "                   'Use `control.linearize()` to convert.'))\n",
    "    sys = env.system.linearize(\n",
    "            np.zeros(env.system.nstates), np.zeros(env.system.ninputs))\n",
    "    sys_xform = env_.system.linearize(\n",
    "            np.zeros(env_.system.nstates), np.zeros(env_.system.ninputs))\n",
    "else:\n",
    "    sys = env.system\n",
    "    sys_xform = env_.system\n",
    "\n",
    "# Linear transformation with\n",
    "k_og, *_ = control.lqr(sys, q, r)\n",
    "sys_opt = sys.feedback(k_og)\n",
    "sys_opt.name = 'sys_opt'\n",
    "\n",
    "# transformed system but with old control law\n",
    "sys_xform_old = sys_xform.feedback(k_og)\n",
    "sys_xform_old.name = 'sys_xform_old'\n",
    "\n",
    "# Optimizing on modified system\n",
    "k, *_ = control.lqr(sys_xform, q, r)\n",
    "sys_xform_opt = sys_xform.feedback(k)\n",
    "sys_xform_opt.name = 'sys_xform_opt'\n",
    "\n",
    "# Optimizing using transformed law\n",
    "feedback = policy_transform(sys, xformA, xformB, k_og)\n",
    "sys_xform_opt2 = sys_xform.feedback(feedback)\n",
    "sys_xform_opt2.name = 'sys_xform_opt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7cecd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(evaluate_lqr(k_og, make_env()))\n",
    "print(evaluate_lqr(k_og, make_xform_env()))\n",
    "print(evaluate_lqr(k, make_xform_env()))\n",
    "print(evaluate_lqr(feedback, make_xform_env()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ff5cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multiple_response_plots([\n",
    "    'old policy on old system',\n",
    "    lambda: plot_env_response(make_env(), x0, k_og),\n",
    "    'old policy on new system',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, k_og),\n",
    "    'Optimal LQR on new system',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, k),\n",
    "    'old policy transformation on new system',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, feedback)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e17cd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation w/ MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02760c0a",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_xform_env()\n",
    "if not isinstance(env.system, control.LinearIOSystem):\n",
    "    warnings.warn(('Must be a linear system in StateSpace from. '\n",
    "                   'Use `control.linearize()` to convert.'))\n",
    "    sys = env.system.linearize(\n",
    "            np.zeros(env.system.nstates), np.zeros(env.system.ninputs))\n",
    "    sys_xform = env_.system.linearize(\n",
    "            np.zeros(env_.system.nstates), np.zeros(env_.system.ninputs))\n",
    "else:\n",
    "    sys = env.system\n",
    "    sys_xform = env_.system\n",
    "state_xform, action_xform = policy_transform(sys, xformA, xformB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcfde7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sys_xform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598c613",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(evaluate_mpc(make_env(), horizon=5, model_env=make_env()))\n",
    "print(evaluate_mpc(make_xform_env(), horizon=10, model_env=make_env()))\n",
    "print(evaluate_mpc(make_xform_env(), horizon=10, model_env=make_xform_env()))\n",
    "print(evaluate_mpc(make_xform_env(), horizon=10, model_env=make_env(), state_xform=state_xform, action_xform=action_xform))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d33bc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Non-linear Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bcc00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def policy_transfrom_nonlinear(sys, xformA=None, xformB=None, ctrl_law=None):\n",
    "    F_A = (lambda x: F_A @ x) if not callable(xformA) else xformA\n",
    "    if isinstance(xformB, InvertibleFunction):\n",
    "        F_B_ = xformB.invert()\n",
    "    else:\n",
    "        F_B_ = np.linalg.pinv(F_B)\n",
    "    if isinstance(B, InvertibleFunction):\n",
    "        B_ = B.invert()\n",
    "    \n",
    "    if ctrl_law is not None:\n",
    "        def func(x):\n",
    "            return B_(F_B_((F_A(A@x) - A@x))) + \\\n",
    "                   B_(F_B_(B@x))\n",
    "        return InvertibleFunction(func, None)\n",
    "    else:\n",
    "        return \\\n",
    "            InvertibleFunction((lambda x: -B_(F_B_((F_A(A@x) - A@x)))), None), \\\n",
    "            InvertibleFunction((lambda x: B_(F_B_(B@x))), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac27d4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_nonlinear_xform_env()\n",
    "if not isinstance(env.system, control.LinearIOSystem):\n",
    "    warnings.warn('Must be a linear system in StateSpace from. Use `control.linearize()` to convert.')\n",
    "    sys = env.system.linearize(\n",
    "            np.zeros(env.system.nstates), np.zeros(env.system.ninputs))\n",
    "    sys_xform = env.system.linearize(\n",
    "            np.zeros(env_.system.nstates), np.zeros(env_.system.ninputs))\n",
    "else:\n",
    "    sys = env.system\n",
    "    sys_xform = env_.system\n",
    "\n",
    "# Linear transformation with\n",
    "k_og, *_ = control.lqr(sys, q, r)\n",
    "sys_opt = sys.feedback(k_og)\n",
    "sys_opt.name = 'sys_opt'\n",
    "\n",
    "# transformed system but with old control law\n",
    "sys_xform_old = sys_xform.feedback(k_og)\n",
    "sys_xform_old.name = 'sys_xform_old'\n",
    "\n",
    "# Optimizing on modified system\n",
    "k, *_ = control.lqr(sys_xform, q, r)\n",
    "sys_xform_opt = sys_xform.feedback(k)\n",
    "sys_xform_opt.name = 'sys_xform_opt'\n",
    "\n",
    "# Optimizing using transformed law\n",
    "feedback = policy_transform(sys, xformA, xformB, k_og)\n",
    "sys_xform_opt2 = sys_xform.feedback(feedback)\n",
    "sys_xform_opt2.name = 'sys_xform_opt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a505bf9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(evaluate_law(k_og, make_env()))\n",
    "print(evaluate_law(k_og, make_xform_env()))\n",
    "print(evaluate_law(k, make_xform_env()))\n",
    "print(evaluate_law(feedback, make_xform_env()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1434f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multiple_response_plots([\n",
    "#     # Cost of using old policy on old system\n",
    "#     lambda: plot_env_response(make_env(), x0, k_og),\n",
    "    # Cost of using old policy on new system\n",
    "    lambda: plot_env_response(make_xform_env(), x0, k_og),\n",
    "    # Optimal LQR cost learned on new system\n",
    "    lambda: plot_env_response(make_xform_env(), x0, k),\n",
    "    # Cost after old policy transformation on new system\n",
    "    lambda: plot_env_response(make_xform_env(), x0, feedback)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65e671",
   "metadata": {},
   "source": [
    "## Data-driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a55a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment config\n",
    "\n",
    "# Whether the knowledge of the source system is known,\n",
    "# or approximated from sampled experiences\n",
    "data_driven_source = True\n",
    "# Whether to assume that the system transformations are known\n",
    "# and not approximate\n",
    "accurate_xfer = False\n",
    "# The factor by which action bounds are relaxed to fully allow the\n",
    "# transformed policy to interact with environment\n",
    "constrained_actions = None # True by default, not implemented yet\n",
    "buffer_episodes=5\n",
    "name = env.__class__.__name__\n",
    "if data_driven_source and not accurate_xfer:\n",
    "    name += 'StochasticAll'\n",
    "elif data_driven_source:\n",
    "    name += 'StochasticSource'\n",
    "elif not accurate_xfer:\n",
    "    name += 'StochasticXfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309975d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train rl policy on original environment\n",
    "agent = learn_rl(make_env(), tensorboard_log=name+'/Source',\n",
    "                 **learn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0056902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_env_response(make_env(), x0, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef354ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env_ = make_xform_env()\n",
    "# linearize a non-linear system to get A,B,C,D representation,\n",
    "# and the resulting pseudo matrix P_s of the source task\n",
    "if isinstance(env.system, control.LinearIOSystem):\n",
    "    _sys_linear = env.system\n",
    "else:\n",
    "    _sys_linear = env.system.linearize(x0 * 0, env.action_space.sample() * 0)\n",
    "# get the pseudo matrix representing source system dynamics\n",
    "if data_driven_source:\n",
    "    xu, x = get_env_samples(env, 1, agent)\n",
    "    P_s = (x @ xu.T) @ np.linalg.pinv(xu @ xu.T)\n",
    "else:\n",
    "    P_s = pseudo_matrix(_sys_linear, env.dt)\n",
    "del _sys_linear\n",
    "# get pseudo matrix representing target system dynamics\n",
    "xu, x = get_env_samples(env_, buffer_episodes, agent)\n",
    "P_t = (x @ xu.T) @ np.linalg.pinv(xu @ xu.T)\n",
    "# get the relationship between source and target systems\n",
    "A_s, B_s, A_t, B_t, F_A, F_B = ab_xform_from_pseudo_matrix(P_s, P_t, env.dt)\n",
    "C_s, D_s = np.eye(len(A_s)), np.zeros_like(B_s)\n",
    "if accurate_xfer:\n",
    "    F_A, F_B = xformA, xformB\n",
    "# generate policy transforms from the source system,\n",
    "# and its relationship to the target system\n",
    "source_system = control.ss(A_s, B_s, C_s, D_s)\n",
    "state_xform, action_xform = policy_transform(source_system, F_A, F_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e307cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('State error:', np.linalg.norm(xformA-F_A))\n",
    "print('Action error:', np.linalg.norm(xformB-F_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tine source policy on target environment\n",
    "agent_new = learn_rl(make_xform_env(),\n",
    "                     reuse_parameters_of=agent,\n",
    "                     tensorboard_log=name+'/Tuned', **learn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e616e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append a transformation to source policy\n",
    "agent_xform = transform_rl_policy(agent, state_xform, action_xform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1ffcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine-tine the transformed policy, except xforms\n",
    "agent_xform_tuned = learn_rl(\n",
    "    make_xform_env(),\n",
    "    reuse_parameters_of=agent_xform,\n",
    "    learnable_transformation=False,\n",
    "    tensorboard_log=name+'/XformedTuned', **learn_kwargs\n",
    ")\n",
    "print('state_xform', agent_xform_tuned.policy.state_xform)\n",
    "print('action_xform', agent_xform_tuned.policy.action_xform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tine the transformed policy, including xforms\n",
    "agent_xform_tuned_all = learn_rl(\n",
    "    make_xform_env(),\n",
    "    reuse_parameters_of=agent_xform,\n",
    "    learnable_transformation=True,\n",
    "    tensorboard_log=name+'/XformedTunedAll', **learn_kwargs\n",
    ")\n",
    "print('state_xform', agent_xform_tuned_all.policy.state_xform.data)\n",
    "print('action_xform', agent_xform_tuned_all.policy.action_xform.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbb528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Source policy on source task')\n",
    "print(evaluate_rl(agent, make_env(), n_eval_episodes=10))\n",
    "print('Reusing source policy')\n",
    "print(evaluate_rl(agent, make_xform_env(), n_eval_episodes=10))\n",
    "print('Tuning source policy')\n",
    "print(evaluate_rl(agent_new, make_xform_env(), n_eval_episodes=10))\n",
    "print('Transforming source policy')\n",
    "print(evaluate_rl(agent_xform, make_xform_env(), n_eval_episodes=10))\n",
    "print('Tuning transformed policy, except for transformations')\n",
    "print(evaluate_rl(agent_xform_tuned, make_xform_env(), n_eval_episodes=10))\n",
    "print('Tuning transformed policy, including transformations')\n",
    "print(evaluate_rl(agent_xform_tuned_all, make_xform_env(), n_eval_episodes=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e603d",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816103ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multiple_response_plots([\n",
    "#     r'$\\pi_s$ on $P_s$ ',\n",
    "#     lambda: plot_env_response(make_env(), x0, agent),\n",
    "    r'$\\pi_s$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent),\n",
    "    r'$\\pi_s^*$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_new, legend=False),\n",
    "    r'$\\pi_t$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_xform, legend=False),\n",
    "    r'$\\pi_t^-$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_xform_tuned, legend=False),\n",
    "    r'$\\pi_t^*$ on $P_t$ ',\n",
    "    lambda: plot_env_response(make_xform_env(), x0, agent_xform_tuned_all, legend=False)\n",
    "], figsize=(6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a075f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remember to specify up-to-date directory\n",
    "# name = env.__class__.__name__\n",
    "df = get_tensorboard_scalar_frame('tensorboard/%s/Source_1' % name)\n",
    "dft = get_tensorboard_scalar_frame('tensorboard/%s/Tuned_1' % name)\n",
    "dfxt = get_tensorboard_scalar_frame('tensorboard/%s/XformedTuned_1' % name)\n",
    "dfxta = get_tensorboard_scalar_frame('tensorboard/%s/XformedTunedAll_1' % name)\n",
    "\n",
    "%matplotlib inline\n",
    "last_tstep = df.index[-1]\n",
    "plt.figure(figsize=(6,2))\n",
    "for i, (frame, label) in enumerate([\n",
    "    (df, '$\\pi_s$ on $P_s$'),\n",
    "    (dft, '$\\pi_s^*$ on $P_t$'),\n",
    "    (dfxt, '$\\pi_t^-$ on $P_t$'),\n",
    "    (dfxta, '$\\pi_t^+$ on $P_t$')\n",
    "]):\n",
    "    if i > 0:\n",
    "        frame.index = frame.index + last_tstep\n",
    "    plt.plot(frame['rollout', 'ep_rew_mean'], label=label)\n",
    "if name.startswith('Simp'):\n",
    "    plt.legend()\n",
    "plt.ylabel('Mean episodic reward')\n",
    "plt.xlabel('Learning time steps')\n",
    "plt.setp(plt.xticks()[1], rotation=15)\n",
    "plt.grid(True, 'both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a95b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Task similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f190f98",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ultimately, task similarity is measuring the performance difference between two tasks in terms of the cost/reward function and the task dynamics. So if two tasks have similar reward functions (same domain, range, mapping), regardless of the nature of state/action space, optimal control function for one task will be optimal for another task.\n",
    "\n",
    "- If kernel of the representative matrices are identical -> same stability points -> tasks similar?\n",
    "    - i.e. if basis vectors of kernels are similar (via dot product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc80282",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Initial state transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea651e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Given a domain of states, how does the matrix $A$ of different systems map them to a different range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241cc48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pend_states = np.asarray([[-np.pi/6, -0.05],\n",
    "                          [-np.pi/6, 0.05],\n",
    "                          [np.pi/6, 0.05],\n",
    "                          [np.pi/6, -0.05]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689664e5",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See how the dynamics matrix A transforms state into derivative\n",
    "from matplotlib.patches import Polygon\n",
    "cm = plt.cm.viridis\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.gca().add_patch(Polygon(pend_states.T, alpha=0.8, label='OG', ec='k', color=cm(0.5)))\n",
    "for i, sys in enumerate(linear_pend[5:]):\n",
    "    plt.gca().add_patch(Polygon(\n",
    "        (pend_states + (sys.A @ pend_states) * 1e-1).T,\n",
    "        ec='k', color=cm(i/len(linear_pend)), alpha=0.2, label='%d: %.2f' % (i, np.linalg.det(sys.A))\n",
    "    ))\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlabel(r'$\\dot{\\theta}$')\n",
    "plt.ylabel(r'$\\partial\\theta/\\partial t$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e0bc2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## State transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1b8de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5, 5)\n",
    "y = np.linspace(-5,5, 5)\n",
    "xgrid, ygrid = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07b74d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "zgrid = xgrid + ygrid\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot3D([min(x), max(x)], [0,0], [0,0], lw=2, c='k')\n",
    "ax.plot3D([0,0], [min(y),max(y)], [0,0], lw=2, c='k')\n",
    "ax.plot3D([0,0], [0,0], [np.min(zgrid),np.max(zgrid)], lw=2, c='k')\n",
    "ax.set_xlabel('a')\n",
    "ax.set_ylabel('$\\epsilon$')\n",
    "ax.set_zlabel('$a^*$')\n",
    "surf = ax.plot_surface(xgrid, ygrid, zgrid, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0eb82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "zgrid = xgrid * ygrid\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot3D([min(x), max(x)], [0,0], [0,0], lw=2, c='k')\n",
    "ax.plot3D([0,0], [min(y),max(y)], [0,0], lw=2, c='k')\n",
    "ax.plot3D([0,0], [0,0], [np.min(zgrid),np.max(zgrid)], lw=2, c='k')\n",
    "ax.set_xlabel('a')\n",
    "ax.set_ylabel('$\\epsilon$')\n",
    "ax.set_zlabel('$a^*$')\n",
    "colors = cm.RdYlGn((np.sign(zgrid) == np.sign(xgrid)).astype(np.float32).T)\n",
    "ax.plot_surface(xgrid, ygrid, np.sign(zgrid) == np.sign(xgrid),\n",
    "                       facecolors=colors, linewidth=0, antialiased=False, alpha=0.6, rstride=1, cstride=1)\n",
    "surf = ax.plot_surface(xgrid, ygrid, zgrid, cmap=None,\n",
    "                       linewidth=0, antialiased=False, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32e213",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Cost surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a06b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Assuming a similar cost function, but different state reachabilities, can the alignment between cost surfaces be a measure of task similarity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d10df0e4cfad4a81e3051546436717ccc1eaea03864256b4a2f98229345d5e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
